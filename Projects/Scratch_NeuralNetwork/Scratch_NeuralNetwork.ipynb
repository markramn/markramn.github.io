{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Coding a neural network from scratch in python"
      ],
      "metadata": {
        "id": "odFnUWs6y9wB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import required packages"
      ],
      "metadata": {
        "id": "3rbYV6FwzEN7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "yPn9hDP4yuII"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from collections import defaultdict\n",
        "import math\n",
        "from math import exp\n",
        "from random import randrange\n",
        "from random import seed\n",
        "from random import random\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn import datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Neural Network"
      ],
      "metadata": {
        "id": "fdaCDMO30DKV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initialize network"
      ],
      "metadata": {
        "id": "hTvHVyU30GK3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize a network\n",
        "\n",
        "def initialize_network(n_inputs, n_hidden, n_outputs):\n",
        "\tnetwork = list()\n",
        " \n",
        "\thidden_layer = [{'weights':[random() for i in range(n_inputs + 1)]} for i in range(n_hidden)]\n",
        "\tnetwork.append(hidden_layer)\n",
        " \n",
        "\toutput_layer = [{'weights':[random() for i in range(n_hidden + 1)]} for i in range(n_outputs)]\n",
        "\tnetwork.append(output_layer)\n",
        " \n",
        "\treturn network"
      ],
      "metadata": {
        "id": "FSScHDuK0J1i"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Showing an example of a basic network given inputs:"
      ],
      "metadata": {
        "id": "uDFvsY8_0csd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seed(1)\n",
        "network = initialize_network(3, 1, 3)\n",
        "for layer in network:\n",
        "\tprint(layer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1A1wvmID0b_k",
        "outputId": "5bf226fe-5726-48f0-b7fd-aa50269affc4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'weights': [0.13436424411240122, 0.8474337369372327, 0.763774618976614, 0.2550690257394217]}]\n",
            "[{'weights': [0.49543508709194095, 0.4494910647887381]}, {'weights': [0.651592972722763, 0.7887233511355132]}, {'weights': [0.0938595867742349, 0.02834747652200631]}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "network"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XyeKh24O7dS1",
        "outputId": "44549e64-d593-418b-c1b8-6d9b53240f86"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[{'weights': [0.13436424411240122,\n",
              "    0.8474337369372327,\n",
              "    0.763774618976614,\n",
              "    0.2550690257394217]}],\n",
              " [{'weights': [0.49543508709194095, 0.4494910647887381]},\n",
              "  {'weights': [0.651592972722763, 0.7887233511355132]},\n",
              "  {'weights': [0.0938595867742349, 0.02834747652200631]}]]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Running the example, you can see that the code prints out each layer one by one. You can see the hidden layer has 1 neurons with 3 input weight plus the bias. The output layer has 3 neurons, each with 1 weight plus the bias."
      ],
      "metadata": {
        "id": "mG90N3hs4J_s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Forward propogation"
      ],
      "metadata": {
        "id": "IvEMgyyt5F3h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Forward propogation is the process of passing a signal through each layer of the network.\n",
        "\n",
        "We can break forward propagation down into three parts:\n",
        "\n",
        "1. Neuron Activation.\n",
        "2. Neuron Transfer.\n",
        "3. Forward Propagation."
      ],
      "metadata": {
        "id": "73QA5Grc5Lnb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Neuron Activation\n",
        "\n",
        "Neuron activation formula:\n",
        "  - *activation = sum(weight_i * input_i) + bias*"
      ],
      "metadata": {
        "id": "7XHr5fn75eFe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate neuron activation for an input\n",
        "def activate(weights, inputs):\n",
        "\tactivation = weights[-1]\n",
        "\tfor i in range(len(weights)-1):\n",
        "\t\tactivation += weights[i] * inputs[i]\n",
        "\treturn activation"
      ],
      "metadata": {
        "id": "f5sjzSWk6G-x"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Neuron Transfer\n",
        "Once a neuron is activated, we need to transfer the activation to see what the neuron output actually is.\n",
        "\n",
        "Sigmoid activation function\n",
        "\n",
        "\n",
        "```\n",
        "output = 1 / (1 + e^(-activation))\n",
        "```"
      ],
      "metadata": {
        "id": "oVNV09sm5hCg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transfer neuron activation\n",
        "def transfer(activation):\n",
        "\treturn 1.0 / (1.0 + np.exp(-activation))"
      ],
      "metadata": {
        "id": "JJRfSxkO6cG0"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Forward Propagation\n",
        "We work through each layer of our network calculating the outputs for each neuron. All of the outputs from one layer become inputs to the neurons on the next layer."
      ],
      "metadata": {
        "id": "5XU_9b6P5gls"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Forward propagate input to a network output\n",
        "def forward_propagate(network, row):\n",
        "\tinputs = row\n",
        "\tfor layer in network:\n",
        "\t\tnew_inputs = []\n",
        "\t\tfor neuron in layer:\n",
        "\t\t\tactivation = activate(neuron['weights'], inputs)\n",
        "\t\t\tneuron['output'] = transfer(activation)\n",
        "\t\t\tnew_inputs.append(neuron['output'])\n",
        "\t\tinputs = new_inputs\n",
        "\treturn inputs"
      ],
      "metadata": {
        "id": "CRtkWWMj0iWA"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Testing so far"
      ],
      "metadata": {
        "id": "aTKAQklY652a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "network = initialize_network(3, 2, 3)"
      ],
      "metadata": {
        "id": "0ZZJ9C8x8JId"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test forward propagation\n",
        "row = [1, 0, 1, None]\n",
        "output = forward_propagate(network, row)\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Za6Im_uE6q5o",
        "outputId": "de80f59e-c0dd-463a-d877-e1c3d6d9d16c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.6901890031754265, 0.8341878143590352, 0.6368243205725128]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Back propogation error\n",
        "\n",
        "Error is calculated between the expected outputs and the outputs forward propagated from the network. These errors are then propagated backward through the network from the output layer to the hidden layer, assigning blame for the error and updating weights as they go.\n",
        "\n",
        "This part is broken down into two sections.\n",
        "\n",
        "1. Transfer Derivative.\n",
        "2. Error Backpropagation."
      ],
      "metadata": {
        "id": "eulfROfi9PAa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Transfer derivative"
      ],
      "metadata": {
        "id": "47r4MimV9beT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the derivative of an neuron output (sigmoid activation)\n",
        "def transfer_derivative(output):\n",
        "\treturn output * (1.0 - output)"
      ],
      "metadata": {
        "id": "GjVOFZ3J6_mv"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Error backpropogation"
      ],
      "metadata": {
        "id": "GaZkHNLu9ebG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Backpropagate error and store in neurons\n",
        "def backward_propagate_error(network, expected):\n",
        "\tfor i in reversed(range(len(network))):\n",
        "\t\tlayer = network[i]\n",
        "\t\terrors = list()\n",
        "\t\tif i != len(network)-1:\n",
        "\t\t\tfor j in range(len(layer)):\n",
        "\t\t\t\terror = 0.0\n",
        "\t\t\t\tfor neuron in network[i + 1]:\n",
        "\t\t\t\t\terror += (neuron['weights'][j] * neuron['delta'])\n",
        "\t\t\t\terrors.append(error)\n",
        "\t\telse:\n",
        "\t\t\tfor j in range(len(layer)):\n",
        "\t\t\t\tneuron = layer[j]\n",
        "\t\t\t\terrors.append(neuron['output'] - expected[j])\n",
        "\t\tfor j in range(len(layer)):\n",
        "\t\t\tneuron = layer[j]\n",
        "\t\t\tneuron['delta'] = errors[j] * transfer_derivative(neuron['output'])"
      ],
      "metadata": {
        "id": "maJuWkz591Ch"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Testing up to this point"
      ],
      "metadata": {
        "id": "9s0rs2mu-wV6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# test backpropagation of error\n",
        "network = [[{'output': 0.7105668883115941, 'weights': [0.13436424411240122, 0.8474337369372327, 0.763774618976614]}],\n",
        "\t\t[{'output': 0.6213859615555266, 'weights': [0.2550690257394217, 0.49543508709194095]}, {'output': 0.6573693455986976, 'weights': [0.4494910647887381, 0.651592972722763]}]]\n",
        "expected = [0, 1]\n",
        "backward_propagate_error(network, expected)\n",
        "for layer in network:\n",
        "\tprint(layer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wv9kqsdN91bO",
        "outputId": "4a8f96da-8aea-416f-9fbe-f1e99cc07da5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'output': 0.7105668883115941, 'weights': [0.13436424411240122, 0.8474337369372327, 0.763774618976614], 'delta': 0.0005348048046610517}]\n",
            "[{'output': 0.6213859615555266, 'weights': [0.2550690257394217, 0.49543508709194095], 'delta': 0.14619064683582808}, {'output': 0.6573693455986976, 'weights': [0.4494910647887381, 0.651592972722763], 'delta': -0.0771723774346327}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Running the example prints the network after the backpropagation of error is complete. You can see that error values are calculated and stored in the neurons for the output layer and the hidden layer."
      ],
      "metadata": {
        "id": "9h_LlM3A_Juo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training neural network\n",
        "\n",
        "Once errors are calculated for each neuron in the network via the back propagation method above, they can be used to update weights.\n",
        "\n",
        "Network weights are updated as follows:\n",
        "\n",
        "\n",
        "```\n",
        "weight = weight - learning_rate * error * input\n",
        "```\n",
        "\n",
        "\n",
        "  "
      ],
      "metadata": {
        "id": "w_abFGGd4_SV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Update network weights with error\n",
        "def update_weights(network, row, l_rate):\n",
        "\tfor i in range(len(network)):\n",
        "\t\tinputs = row[:-1]\n",
        "\t\tif i != 0:\n",
        "\t\t\tinputs = [neuron['output'] for neuron in network[i - 1]]\n",
        "\t\tfor neuron in network[i]:\n",
        "\t\t\tfor j in range(len(inputs)):\n",
        "\t\t\t\tneuron['weights'][j] -= l_rate * neuron['delta'] * inputs[j]\n",
        "\t\t\tneuron['weights'][-1] -= l_rate * neuron['delta']"
      ],
      "metadata": {
        "id": "UE9RWYRF-5Gc"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train a network for a fixed number of epochs\n",
        "def train_network(network, train, l_rate, n_epoch, n_outputs):\n",
        "\tfor epoch in range(n_epoch):\n",
        "\t\tsum_error = 0\n",
        "\t\tfor row in train:\n",
        "\t\t\toutputs = forward_propagate(network, row)\n",
        "\t\t\texpected = [0 for i in range(n_outputs)]\n",
        "\t\t\texpected[row[-1]] = 1\n",
        "\t\t\tsum_error += sum([(expected[i]-outputs[i])**2 for i in range(len(expected))])\n",
        "\t\t\tbackward_propagate_error(network, expected)\n",
        "\t\t\tupdate_weights(network, row, l_rate)\n",
        "\t\tprint('>epoch=%d, lrate=%.3f, error=%.3f' % (epoch, l_rate, sum_error))"
      ],
      "metadata": {
        "id": "ZVCFWxd-5lLo"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Testing up until now"
      ],
      "metadata": {
        "id": "y-7EyG4H5t5s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test training backprop algorithm\n",
        "seed(1)\n",
        "dataset = [[2.7810836,2.550537003,0],\n",
        "\t[1.465489372,2.362125076,0],\n",
        "\t[3.396561688,4.400293529,0],\n",
        "\t[1.38807019,1.850220317,0],\n",
        "\t[3.06407232,3.005305973,0],\n",
        "\t[7.627531214,2.759262235,1],\n",
        "\t[5.332441248,2.088626775,1],\n",
        "\t[6.922596716,1.77106367,1],\n",
        "\t[8.675418651,-0.242068655,1],\n",
        "\t[7.673756466,3.508563011,1]]\n",
        "n_inputs = len(dataset[0]) - 1\n",
        "n_outputs = len(set([row[-1] for row in dataset]))\n",
        "network = initialize_network(n_inputs, 2, n_outputs)\n",
        "train_network(network, dataset, 0.5, 20, n_outputs)\n",
        "for layer in network:\n",
        "\tprint(layer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NKihRjms5weS",
        "outputId": "4f2d7707-1769-4a19-8b18-f39ff842efb0"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">epoch=0, lrate=0.500, error=6.350\n",
            ">epoch=1, lrate=0.500, error=5.531\n",
            ">epoch=2, lrate=0.500, error=5.221\n",
            ">epoch=3, lrate=0.500, error=4.951\n",
            ">epoch=4, lrate=0.500, error=4.519\n",
            ">epoch=5, lrate=0.500, error=4.173\n",
            ">epoch=6, lrate=0.500, error=3.835\n",
            ">epoch=7, lrate=0.500, error=3.506\n",
            ">epoch=8, lrate=0.500, error=3.192\n",
            ">epoch=9, lrate=0.500, error=2.898\n",
            ">epoch=10, lrate=0.500, error=2.626\n",
            ">epoch=11, lrate=0.500, error=2.377\n",
            ">epoch=12, lrate=0.500, error=2.153\n",
            ">epoch=13, lrate=0.500, error=1.953\n",
            ">epoch=14, lrate=0.500, error=1.774\n",
            ">epoch=15, lrate=0.500, error=1.614\n",
            ">epoch=16, lrate=0.500, error=1.472\n",
            ">epoch=17, lrate=0.500, error=1.346\n",
            ">epoch=18, lrate=0.500, error=1.233\n",
            ">epoch=19, lrate=0.500, error=1.132\n",
            "[{'weights': [-1.4688375095432327, 1.850887325439514, 1.0858178629550297], 'output': 0.029980305604426185, 'delta': 0.0059546604162323625}, {'weights': [0.37711098142462157, -0.0625909894552989, 0.2765123702642716], 'output': 0.9456229000211323, 'delta': -0.0026279652850863837}]\n",
            "[{'weights': [2.515394649397849, -0.3391927502445985, -0.9671565426390275], 'output': 0.23648794202357587, 'delta': 0.04270059278364587}, {'weights': [-2.5584149848484263, 1.0036422106209202, 0.42383086467582715], 'output': 0.7790535202438367, 'delta': -0.03803132596437354}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Making Predictions\n",
        "\n",
        "We have already seen how to forward-propagate an input pattern to get an output. This is all we need to do to make a prediction. We can use the output values themselves directly as the probability of a pattern belonging to each output class.\n",
        "\n",
        "It may be more useful to turn this output back into a crisp class prediction. We can do this by selecting the class value with the larger probability. This is also called the arg max function."
      ],
      "metadata": {
        "id": "fSXeO9VX7Cdn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make a prediction with a network\n",
        "def predict(network, row):\n",
        "\toutputs = forward_propagate(network, row)\n",
        "\treturn outputs.index(max(outputs))"
      ],
      "metadata": {
        "id": "MJvVij3b7BIW"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test making predictions with the network\n",
        "dataset = \\\n",
        "  [[2.7810836,2.550537003,0],\n",
        "\t[1.2,2.362125076,0],\n",
        "\t[3.396561688,4.400293529,0],\n",
        "\t[1.38807019,1.850220317,0],\n",
        "\t[3.06407232,3.005305973,0],\n",
        "\t[7.627531214,2.759262235,1],\n",
        "\t[5.332441248,2.088626775,1],\n",
        "\t[6.922596716,1.77106367,1],\n",
        "\t[8.675418651,-0.242068655,1],\n",
        "\t[7.673756466,3.508563011,1]]\n",
        "  \n",
        "network = [[{'weights': [-1.482313569067226, 1.8308790073202204, 1.078381922048799]}, {'weights': [0.23244990332399884, 0.3621998343835864, 0.40289821191094327]}],\n",
        "\t[{'weights': [2.5001872433501404, 0.7887233511355132, -1.1026649757805829]}, {'weights': [-2.429350576245497, 0.8357651039198697, 1.0699217181280656]}]]\n",
        "  \n",
        "for row in dataset:\n",
        "\tprediction = predict(network, row)\n",
        "\tprint('Expected=%d, Got=%d' % (row[-1], prediction))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74Pp62qg5w-J",
        "outputId": "b1d2c7e1-636c-4834-d9ac-3d20509400bb"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Expected=0, Got=0\n",
            "Expected=0, Got=0\n",
            "Expected=0, Got=0\n",
            "Expected=0, Got=0\n",
            "Expected=0, Got=0\n",
            "Expected=1, Got=1\n",
            "Expected=1, Got=1\n",
            "Expected=1, Got=1\n",
            "Expected=1, Got=1\n",
            "Expected=1, Got=1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Complete implementation"
      ],
      "metadata": {
        "id": "PoDBSFuE7rZm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert string column to float\n",
        "def str_column_to_float(dataset, column):\n",
        "\tfor row in dataset:\n",
        "\t\trow[column] = float(row[column].strip())\n",
        "\n",
        "# Convert string column to integer\n",
        "def str_column_to_int(dataset, column):\n",
        "\tclass_values = [row[column] for row in dataset]\n",
        "\tunique = set(class_values)\n",
        "\tlookup = dict()\n",
        "\tfor i, value in enumerate(unique):\n",
        "\t\tlookup[value] = i\n",
        "\tfor row in dataset:\n",
        "\t\trow[column] = lookup[row[column]]\n",
        "\treturn lookup"
      ],
      "metadata": {
        "id": "xHzEpAyh7vAG"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the min and max values for each column\n",
        "def dataset_minmax(dataset):\n",
        "\tminmax = list()\n",
        "\tstats = [[min(column), max(column)] for column in zip(*dataset)]\n",
        "\treturn stats\n",
        "\n",
        "# Rescale dataset columns to the range 0-1\n",
        "def normalize_dataset(dataset, minmax):\n",
        "\tfor row in dataset:\n",
        "\t\tfor i in range(len(row)-1):\n",
        "\t\t\trow[i] = (row[i] - minmax[i][0]) / (minmax[i][1] - minmax[i][0])"
      ],
      "metadata": {
        "id": "PVmWgXpG7zor"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split a dataset into k folds\n",
        "def cross_validation_split(dataset, n_folds):\n",
        "  dataset_split = list()\n",
        "  dataset_copy = list(dataset)\n",
        "  fold_size = int(len(dataset) / n_folds)\n",
        "  for i in range(n_folds):\n",
        "    fold = list()\n",
        "    while len(fold) < fold_size:\n",
        "      index = randrange(len(dataset_copy))\n",
        "      fold.append(dataset_copy.pop(index))\n",
        "    dataset_split.append(fold)\n",
        "  return dataset_split"
      ],
      "metadata": {
        "id": "2XEvvdtF73Sj"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate accuracy percentage\n",
        "def accuracy_metric(actual, predicted):\n",
        "\tcorrect = 0\n",
        "\tfor i in range(len(actual)):\n",
        "\t\tif actual[i] == predicted[i]:\n",
        "\t\t\tcorrect += 1\n",
        "\treturn correct / float(len(actual)) * 100.0"
      ],
      "metadata": {
        "id": "wvr_Nz9t74dn"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate an algorithm using a cross validation split\n",
        "def evaluate_algorithm(dataset, algorithm, n_folds, *args):\n",
        "  folds = cross_validation_split(dataset, n_folds)\n",
        "  scores = list()\n",
        "  for fold in folds:\n",
        "\n",
        "    train_set = list(folds)\n",
        "    train_set.remove(fold)\n",
        "    train_set = sum(train_set, [])\n",
        "    test_set = list()\n",
        "    for row in fold:\n",
        "      row_copy = list(row)\n",
        "      test_set.append(row_copy)\n",
        "      row_copy[-1] = None\n",
        "\n",
        "  predicted = algorithm(train_set, test_set, *args)\n",
        "  actual = [row[-1] for row in fold]\n",
        "  accuracy = accuracy_metric(actual, predicted)\n",
        "  scores.append(accuracy)\n",
        "  return scores"
      ],
      "metadata": {
        "id": "Sfmr-YUA76u4"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate neuron activation for an input\n",
        "def activate(weights, inputs):\n",
        "\tactivation = weights[-1]\n",
        "\tfor i in range(len(weights)-1):\n",
        "\t\tactivation += weights[i] * inputs[i]\n",
        "\treturn activation\n",
        "\n",
        "# Transfer neuron activation\n",
        "def transfer(activation):\n",
        "\treturn 1.0 / (1.0 + exp(-activation))\n",
        "\n",
        "# Forward propagate input to a network output\n",
        "def forward_propagate(network, row):\n",
        "\tinputs = row\n",
        "\tfor layer in network:\n",
        "\t\tnew_inputs = []\n",
        "\t\tfor neuron in layer:\n",
        "\t\t\tactivation = activate(neuron['weights'], inputs)\n",
        "\t\t\tneuron['output'] = transfer(activation)\n",
        "\t\t\tnew_inputs.append(neuron['output'])\n",
        "\t\tinputs = new_inputs\n",
        "\treturn inputs\n",
        "\n",
        "# Calculate the derivative of an neuron output\n",
        "def transfer_derivative(output):\n",
        "\treturn output * (1.0 - output)\n",
        "\n",
        "# Backpropagate error and store in neurons\n",
        "def backward_propagate_error(network, expected):\n",
        "\tfor i in reversed(range(len(network))):\n",
        "\t\tlayer = network[i]\n",
        "\t\terrors = list()\n",
        "\t\tif i != len(network)-1:\n",
        "\t\t\tfor j in range(len(layer)):\n",
        "\t\t\t\terror = 0.0\n",
        "\t\t\t\tfor neuron in network[i + 1]:\n",
        "\t\t\t\t\terror += (neuron['weights'][j] * neuron['delta'])\n",
        "\t\t\t\terrors.append(error)\n",
        "\t\telse:\n",
        "\t\t\tfor j in range(len(layer)):\n",
        "\t\t\t\tneuron = layer[j]\n",
        "\t\t\t\terrors.append(neuron['output'] - expected[j])\n",
        "\t\tfor j in range(len(layer)):\n",
        "\t\t\tneuron = layer[j]\n",
        "\t\t\tneuron['delta'] = errors[j] * transfer_derivative(neuron['output'])\n",
        "\n",
        "# Update network weights with error\n",
        "def update_weights(network, row, l_rate):\n",
        "\tfor i in range(len(network)):\n",
        "\t\tinputs = row[:-1]\n",
        "\t\tif i != 0:\n",
        "\t\t\tinputs = [neuron['output'] for neuron in network[i - 1]]\n",
        "\t\tfor neuron in network[i]:\n",
        "\t\t\tfor j in range(len(inputs)):\n",
        "\t\t\t\tneuron['weights'][j] -= l_rate * neuron['delta'] * inputs[j]\n",
        "\t\t\tneuron['weights'][-1] -= l_rate * neuron['delta']\n",
        "\n",
        "# Train a network for a fixed number of epochs\n",
        "def train_network(network, train, l_rate, n_epoch, n_outputs):\n",
        "\tfor epoch in range(n_epoch):\n",
        "\t\tfor row in train:\n",
        "\t\t\toutputs = forward_propagate(network, row)\n",
        "\t\t\texpected = [0 for i in range(n_outputs)]\n",
        "\t\t\texpected[row[-1]] = 1\n",
        "\t\t\tbackward_propagate_error(network, expected)\n",
        "\t\t\tupdate_weights(network, row, l_rate)\n",
        "\n",
        "# Initialize a network\n",
        "def initialize_network(n_inputs, n_hidden, n_outputs):\n",
        "\tnetwork = list()\n",
        "\thidden_layer = [{'weights':[random() for i in range(n_inputs + 1)]} for i in range(n_hidden)]\n",
        "\tnetwork.append(hidden_layer)\n",
        "\toutput_layer = [{'weights':[random() for i in range(n_hidden + 1)]} for i in range(n_outputs)]\n",
        "\tnetwork.append(output_layer)\n",
        "\treturn network\n",
        "\n",
        "# Make a prediction with a network\n",
        "def predict(network, row):\n",
        "\toutputs = forward_propagate(network, row)\n",
        "\treturn outputs.index(max(outputs))\n",
        "\n",
        "# Backpropagation Algorithm With Stochastic Gradient Descent\n",
        "def back_propagation(train, test, l_rate, n_epoch, n_hidden):\n",
        "  print(train)\n",
        "  n_inputs = len(train[0]) - 1\n",
        "  n_outputs = len(set([row[-1] for row in train]))\n",
        "  network = initialize_network(n_inputs, n_hidden, n_outputs)\n",
        "  train_network(network, train, l_rate, n_epoch, n_outputs)\n",
        "  predictions = list()\n",
        "  for row in test:\n",
        "    prediction = predict(network, row)\n",
        "    predictions.append(prediction)\n",
        "    \n",
        "  return(predictions)"
      ],
      "metadata": {
        "id": "duCDXw6p7U2C"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load a CSV file\n",
        "def load_csv(filename):\n",
        "\tdataset = list()\n",
        "\twith open(filename, 'r') as file:\n",
        "\t\tcsv_reader = reader(file)\n",
        "\t\tfor row in csv_reader:\n",
        "\t\t\tif not row:\n",
        "\t\t\t\tcontinue\n",
        "\t\t\tdataset.append(row)\n",
        "\treturn dataset"
      ],
      "metadata": {
        "id": "QvXJ6qPxvGV2"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test Backprop on Seeds dataset\n",
        "seed(1)\n",
        "# load and prepare data\n",
        "filename = '/content/wheat-seeds.csv'\n",
        "dataset = load_csv(filename)"
      ],
      "metadata": {
        "id": "LYC7_f2L9fcl"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(dataset[0])-1):\n",
        "\tstr_column_to_float(dataset, i)\n",
        "# convert class column to integers\n",
        "str_column_to_int(dataset, len(dataset[0])-1)\n",
        "# normalize input variables\n",
        "minmax = dataset_minmax(dataset)\n",
        "normalize_dataset(dataset, minmax)\n",
        "# evaluate algorithm\n",
        "n_folds = 5\n",
        "l_rate = 0.3\n",
        "n_epoch = 500\n",
        "n_hidden = 5\n",
        "scores = evaluate_algorithm(dataset, back_propagation, n_folds, l_rate, n_epoch, n_hidden)\n",
        "print('Scores: %s' % scores)\n",
        "print('Mean Accuracy: %.3f%%' % (sum(scores)/float(len(scores))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qCo3GmvovAW7",
        "outputId": "2958ddcd-06cf-45bf-eb5b-91e954d63d93"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scores: [92.85714285714286, 92.85714285714286, 97.61904761904762, 95.23809523809523, 88.09523809523809]\n",
            "Mean Accuracy: 93.333%\n"
          ]
        }
      ]
    }
  ]
}